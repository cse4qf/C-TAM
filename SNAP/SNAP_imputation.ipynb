{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This script imputes Supplemental Nutrition Assistance Program (SNAP) recipients dollar benefit amount to match the aggregates with United States Department of Agriculture (USDA) statistics for SNAP. In this current version, we used 2015 CPS data and USDA FY2014 annual reports on SNAP. Please refer to the documentation in the same folder for more details on methodology and assumptions. The output this script is a personal level dataset that contains CPS household level sequence (h_seq), individual participation indicator (snap_participation, 0 - not a recipient, 1 - current recipient on file, 2 - imputed recipient), and benefit amount.\n",
    "\n",
    "Input: 2015 CPS (cpsmar2015t.csv), number of recipients and their benefits amount by state in 2014 (Administrative.csv)\n",
    "\n",
    "Output: SNAP_Imputation.csv\n",
    "\n",
    "Additional Source links: http://www.fns.usda.gov/pd/supplemental-nutrition-assistance-program-snap (zipfile for FY69 through FY16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comm6\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (5,22,23,28,80,187,273) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "CPS_dataset = pd.read_csv('asec2015_pubuse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables we use in CPS:\n",
    "columns_to_keep = ['hfoodsp','hfdval','h_numper','h_seq','a_age','marsupwt','moop','hhi_yn','chsp_val',\n",
    "                   'gestfips','pedisout','pedisdrs','pedisear', 'pedisrem','pediseye', 'pedisphy', \n",
    "                   'vet_typ1','vet_yn','pemlr','filestat','wsal_val','semp_val','frse_val',\n",
    "                   'ss_val','rtm_val','oi_val','oi_off','int_yn','uc_yn', 'wc_yn','ss_yn', 'paw_yn',\n",
    "                   'uc_val','int_val','hfoodmo', 'sur_yn', 'hcsp_yn', 'hed_yn', 'mcaid', 'mcare',\n",
    "                   'fsup_wgt', 'hsup_wgt','h_respnm', 'ssi_yn','a_exprrp', 'perrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset = CPS_dataset[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recipient or not\n",
    "CPS_dataset.hfoodsp = np.where(CPS_dataset.hfoodsp == \"Yes\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare household level data\n",
    "household_SNAP = CPS_dataset.groupby('h_seq')['hfoodsp'].mean()\n",
    "household_size = CPS_dataset.groupby('h_seq')['h_numper'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Earned income\n",
    "wage = pd.to_numeric(np.where(CPS_dataset.wsal_val!= 'None or not in universe', CPS_dataset.wsal_val, 0))\n",
    "self_employed1 = pd.to_numeric(np.where(CPS_dataset.semp_val!= 'None or not in universe', CPS_dataset.semp_val, 0))\n",
    "self_employed2 = pd.to_numeric(np.where(CPS_dataset.frse_val!= 'None or not in universe', CPS_dataset.frse_val, 0))\n",
    "p_earned = wage + self_employed1 + self_employed2 #individual earned income\n",
    "p_earned = 0.8 * p_earned #for net income calculation, there is a 20% deduction in earned income\n",
    "CPS_dataset['p_earned'] = p_earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unearned income\n",
    "ss = pd.to_numeric(np.where(CPS_dataset.ss_val!='None or not in universe', CPS_dataset.ss_val, 0))\n",
    "pension = pd.to_numeric(np.where(CPS_dataset.rtm_val!='None or not in universe', CPS_dataset.rtm_val, 0))\n",
    "disability = pd.to_numeric(np.where(CPS_dataset.oi_off=='State disability payments', CPS_dataset.oi_val, 0))\n",
    "unemploy = pd.to_numeric(np.where(CPS_dataset.uc_yn=='Yes', CPS_dataset.uc_val, 0))\n",
    "interest = pd.to_numeric(np.where(CPS_dataset.int_yn=='Yes', CPS_dataset.int_val, 0))\n",
    "p_unearned = ss + pension + disability + unemploy + interest #individual unearned income\n",
    "CPS_dataset['p_unearned'] = p_unearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Net Income\n",
    "CPS_dataset['hh_net_income'] = p_earned + p_unearned\n",
    "hh_net_income = CPS_dataset.groupby('h_seq')['hh_net_income'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP = DataFrame(household_SNAP.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['hh_net'] = hh_net_income\n",
    "hh_SNAP['hh_size'] = household_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.columns = ['indicator', 'hh_net','hh_size'] #indicator is hfoodsp, a dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net income deduction\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size <=3, hh_SNAP.hh_net-155*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size ==4, hh_SNAP.hh_net-168*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size ==5, hh_SNAP.hh_net-197*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size >=6, hh_SNAP.hh_net-226*12, hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#medical deduction\n",
    "#age over 60\n",
    "CPS_dataset.a_age = np.where(CPS_dataset.a_age == \"80-84 years of age\",\n",
    "                             random.randrange(80, 84),\n",
    "                             CPS_dataset.a_age)\n",
    "CPS_dataset.a_age = np.where(CPS_dataset.a_age == \"85+ years of age\",\n",
    "                             random.randrange(85, 95),\n",
    "                             CPS_dataset.a_age)\n",
    "CPS_dataset.a_age = pd.to_numeric(CPS_dataset.a_age)\n",
    "#disabled\n",
    "CPS_dataset['disability'] = np.zeros(len(CPS_dataset))\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisdrs == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisear == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pediseye == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisout == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisphy == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisrem == 'Yes', 1, CPS_dataset.disability)\n",
    "#deduction of more than $35 for a month\n",
    "CPS_dataset.hhi_yn = np.where(CPS_dataset.hhi_yn == 'Yes', 1, 0)\n",
    "CPS_dataset.moop = np.where(CPS_dataset.moop != 'NIU', CPS_dataset.moop, 0)\n",
    "CPS_dataset['medical'] = np.zeros(len(CPS_dataset))\n",
    "CPS_dataset.medical = np.where((CPS_dataset.hhi_yn == 0), CPS_dataset.moop, 0)\n",
    "CPS_dataset.medical = np.where((CPS_dataset.disability == 1.0)|(CPS_dataset.a_age >= 60), CPS_dataset.moop, 0)\n",
    "CPS_dataset.medical = pd.to_numeric(CPS_dataset.medical)\n",
    "hh_medical = CPS_dataset.groupby('h_seq')['medical'].sum()\n",
    "hh_SNAP['hh_medical'] = hh_medical\n",
    "hh_SNAP.hh_net = np.where(hh_medical > 35*12, hh_SNAP.hh_net-(hh_medical-35*12), hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['disability'] = CPS_dataset.groupby('h_seq')['disability'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#child support\n",
    "CPS_dataset.chsp_val = np.where(CPS_dataset.chsp_val == \"NIU\", 0, CPS_dataset.chsp_val)\n",
    "CPS_dataset.chsp_val = pd.to_numeric(CPS_dataset.chsp_val)\n",
    "hh_child = CPS_dataset.groupby('h_seq')['chsp_val'].sum()\n",
    "hh_SNAP['hh_child'] = hh_child\n",
    "hh_SNAP.hh_net = hh_SNAP.hh_net - hh_SNAP.hh_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset['children_yn'] = np.where(CPS_dataset.a_age<=18,1,0)\n",
    "hh_SNAP['child_yn'] = CPS_dataset.groupby('h_seq')['children_yn'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.hh_net = hh_SNAP.hh_net - (10+290)*12 #dependent care; excess shelter. All based on SNAP official average\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_net <0, 0, hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keep a reasonable subset\n",
    "hh_SNAP.hh_net = np.where((hh_SNAP.hh_net > 5490 * 12) & (hh_SNAP.indicator==0), -100, hh_SNAP.hh_net)\n",
    "hh_SNAP = hh_SNAP[hh_SNAP.hh_net>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.to_csv('check3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['intercept'] = np.ones(len(hh_SNAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other welfare program participation indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.ssi_yn = np.where(CPS_dataset.ssi_yn=='Yes', 1, 0)\n",
    "hh_SNAP['ssi_yn'] = CPS_dataset.groupby('h_seq')['ssi_yn'].sum()\n",
    "hh_SNAP['ssi_yn'] = np.where(hh_SNAP.ssi_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.ss_yn = np.where(CPS_dataset.ss_yn=='Yes', 1, 0)\n",
    "hh_SNAP['ss_yn'] = CPS_dataset.groupby('h_seq')['ss_yn'].sum()\n",
    "hh_SNAP['ss_yn'] = np.where(hh_SNAP.ss_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.wc_yn = np.where(CPS_dataset.wc_yn=='Yes', 1, 0)\n",
    "hh_SNAP['wc_yn'] = CPS_dataset.groupby('h_seq')['wc_yn'].sum()\n",
    "hh_SNAP['wc_yn'] = np.where(hh_SNAP.wc_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.uc_yn = np.where(CPS_dataset.uc_yn=='Yes', 1, 0)\n",
    "hh_SNAP['uc_yn'] = CPS_dataset.groupby('h_seq')['uc_yn'].sum()\n",
    "hh_SNAP['uc_yn'] = np.where(hh_SNAP.uc_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.paw_yn = np.where(CPS_dataset.paw_yn=='Yes', 1, 0)\n",
    "hh_SNAP['paw_yn'] = CPS_dataset.groupby('h_seq')['paw_yn'].sum()\n",
    "hh_SNAP['paw_yn'] = np.where(hh_SNAP.paw_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.vet_yn = np.where(CPS_dataset.vet_yn=='Yes', 1, 0)\n",
    "hh_SNAP['vet_yn'] = CPS_dataset.groupby('h_seq')['vet_yn'].sum()\n",
    "hh_SNAP['vet_yn'] = np.where(hh_SNAP.vet_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPS_dataset.sur_yn = np.where(CPS_dataset.sur_yn=='Yes', 1, 0)\n",
    "hh_SNAP['sur_yn'] = CPS_dataset.groupby('h_seq')['sur_yn'].sum()\n",
    "hh_SNAP['sur_yn'] = np.where(hh_SNAP.sur_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.mcare = np.where(CPS_dataset.mcare=='Yes', 1, 0)\n",
    "hh_SNAP['mcare'] = CPS_dataset.groupby('h_seq')['mcare'].sum()\n",
    "hh_SNAP['mcare'] = np.where(hh_SNAP.mcare>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.mcaid = np.where(CPS_dataset.mcaid=='Yes', 1, 0)\n",
    "hh_SNAP['mcaid'] = CPS_dataset.groupby('h_seq')['mcaid'].sum()\n",
    "hh_SNAP['mcaid'] = np.where(hh_SNAP.mcaid>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset['ABAWD'] = np.where((CPS_dataset.a_age>18)&(CPS_dataset.a_age<49)&(CPS_dataset.disability==0), 1, 0)\n",
    "CPS_dataset['ABAWD'] = np.where((CPS_dataset.a_exprrp=='Reference person without')|(CPS_dataset.a_exprrp=='Partner/roommate'), \n",
    "                                CPS_dataset.ABAWD, 0)\n",
    "hh_SNAP['ABAWD'] = CPS_dataset.groupby('h_seq')['ABAWD'].mean()\n",
    "hh_SNAP['ABAWD'] = np.where(hh_SNAP.ABAWD!=0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_net > 5490 * 12, -100, hh_SNAP.hh_net)\n",
    "hh_SNAP = hh_SNAP[hh_SNAP.hh_net>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.293053\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              indicator   No. Observations:                52906\n",
      "Model:                          Logit   Df Residuals:                    52891\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Mon, 31 Jul 2017   Pseudo R-squ.:                  0.3548\n",
      "Time:                        11:50:00   Log-Likelihood:                -15504.\n",
      "converged:                       True   LL-Null:                       -24030.\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "hh_net     -7.001e-05   1.23e-06    -56.829      0.000   -7.24e-05   -6.76e-05\n",
      "hh_size        0.1732      0.020      8.492      0.000       0.133       0.213\n",
      "disability     0.3341      0.028     11.795      0.000       0.279       0.390\n",
      "child_yn       0.2334      0.025      9.207      0.000       0.184       0.283\n",
      "ABAWD          0.5860      0.058     10.043      0.000       0.472       0.700\n",
      "ssi_yn         0.5582      0.048     11.722      0.000       0.465       0.652\n",
      "intercept     -2.1231      0.040    -52.665      0.000      -2.202      -2.044\n",
      "uc_yn          0.9181      0.069     13.356      0.000       0.783       1.053\n",
      "paw_yn         1.8041      0.091     19.761      0.000       1.625       1.983\n",
      "vet_yn        -0.7084      0.100     -7.050      0.000      -0.905      -0.512\n",
      "sur_yn        -0.7920      0.123     -6.464      0.000      -1.032      -0.552\n",
      "mcare         -0.2561      0.049     -5.223      0.000      -0.352      -0.160\n",
      "mcaid          1.6350      0.034     47.613      0.000       1.568       1.702\n",
      "ss_yn          0.5570      0.048     11.654      0.000       0.463       0.651\n",
      "wc_yn         -0.1216      0.151     -0.806      0.420      -0.417       0.174\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Regression\n",
    "model = sm.Logit(endog= hh_SNAP.indicator, exog= hh_SNAP[['hh_net', 'hh_size','disability','child_yn','ABAWD',\n",
    "                                                          'ssi_yn','intercept', 'uc_yn', 'paw_yn', 'vet_yn',\n",
    "                                                          'sur_yn', 'mcare', 'mcaid', 'ss_yn', 'wc_yn']]).fit()\n",
    "#print model.summary()\n",
    "print (model.summary()) #edited print() function to work with Python 3.6 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keep household with 1 member\n",
    "hh_SNAP['probs'] = model.predict()\n",
    "probs = hh_SNAP.probs[hh_SNAP.hh_size==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16737"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hh_SNAP[hh_SNAP.hh_size==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16737 52906\n"
     ]
    }
   ],
   "source": [
    "#print len(probs), len(hh_SNAP)\n",
    "print (len(probs), len(hh_SNAP)) #edited print() function to work with Python 3.6 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare household's weights; states; SNAP value\n",
    "household_marsupwt = CPS_dataset.groupby('h_seq')['hsup_wgt'].mean()\n",
    "hh_SNAP['hh_marsupwt'] = household_marsupwt\n",
    "\n",
    "household_gestfips = CPS_dataset.groupby('h_seq')['gestfips'].mean()\n",
    "hh_SNAP['hh_gestfips'] = household_gestfips\n",
    "\n",
    "CPS_dataset.hfdval = np.where(CPS_dataset.hfdval!= 'Not in universe', CPS_dataset.hfdval, 0)\n",
    "CPS_dataset.hfdval = pd.to_numeric(CPS_dataset.hfdval)\n",
    "household_hfdval = CPS_dataset.groupby('h_seq')['hfdval'].mean()\n",
    "hh_SNAP['hh_hfdval'] = household_hfdval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare household's length of being recipients\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == 'Not in universe', 0, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == '12 Months', 12, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == '1 month', 1, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = pd.to_numeric(CPS_dataset.hfoodmo)\n",
    "household_hfoodmo = CPS_dataset.groupby('h_seq')['hfoodmo'].mean()\n",
    "hh_SNAP['hh_hfoodmo'] = household_hfoodmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import administrative level data\n",
    "admin = pd.read_csv('SNAP_Administrative.csv',\n",
    "                    dtype={ 'Household number': np.float,'Average household benefit': np.float, \n",
    "                            'Total': np.float, 'Individual number': np.float})\n",
    "admin.index = admin.Fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CPS total benefits and Administrative total benefits\n",
    "state_benefit = {}\n",
    "state_recipients = {}\n",
    "for state in admin.Fips:\n",
    "    this_state = (hh_SNAP.hh_gestfips==state)\n",
    "    CPS_totalb = (hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt / hh_SNAP.hh_hfoodmo)[this_state].sum()/1000000 #in million, per month\n",
    "    admin_totalb =  admin.Total[state] /12 /1000000 # in million, per month\n",
    "    CPS_totaln = (hh_SNAP.hh_marsupwt[this_state&hh_SNAP.indicator==1]*hh_SNAP.hh_hfoodmo/12).sum()/1000 # in thousand, per month\n",
    "    admin_totaln =  admin[\"Household number\"][state] /1000 #household in thousand, per month\n",
    "    CPS_totalnindividual = (hh_SNAP.hh_marsupwt* hh_SNAP.hh_size[this_state&hh_SNAP.indicator==1]*hh_SNAP.hh_hfoodmo/12).sum()/1000 # in thousand, per month\n",
    "    admin_totalnindividual =  admin[\"Individual number\"][state] /1000 #individual in thousand, per month\n",
    "    \n",
    "    temp = [admin.State[state], CPS_totalb, admin_totalb, CPS_totaln, admin_totaln, CPS_totalnindividual, admin_totalnindividual]\n",
    "    state_benefit[state] = temp\n",
    "    \n",
    "pre_augment_benefit = DataFrame(state_benefit).transpose()\n",
    "pre_augment_benefit.columns = ['State', 'CPS total benefits(monthly)','Admin total benefits(monthly)',\n",
    "                               'CPS total household recipient(monthly)','Admin total household recipient(monthly)',\n",
    "                               'CPS total individual recipient(monthly)','Admin total individual recipient(monthly)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_augment_benefit.to_csv('pre-blow-up.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# caculate difference of SNAP stats and CPS aggregates on recipients number\n",
    "# by state\n",
    "diff = {'Fips':[],'Difference in Population':[],'Mean Benefit':[],'CPS Population':[],'SNAP Population':[]}\n",
    "diff['Fips'] = admin.Fips\n",
    "current = (hh_SNAP.indicator==1)\n",
    "for FIPS in admin.Fips:\n",
    "        this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "        current_tots = (hh_SNAP.hh_marsupwt[current&this_state]*hh_SNAP.hh_hfoodmo/12).sum()\n",
    "        valid_num = (hh_SNAP.hh_marsupwt[current&this_state]*hh_SNAP.hh_hfoodmo/12).sum() + 0.0000001\n",
    "        current_mean = ((hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt / hh_SNAP.hh_hfoodmo)[current&this_state].sum())/valid_num\n",
    "        diff['CPS Population'].append(current_tots)\n",
    "        diff['SNAP Population'].append(float(admin[\"Household number\"][admin.Fips == FIPS]))\n",
    "        diff['Difference in Population'].append(float(admin[\"Household number\"][admin.Fips == FIPS])- current_tots)\n",
    "        diff['Mean Benefit'].append(current_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = DataFrame(diff)\n",
    "d = d[['Fips', 'Mean Benefit', 'Difference in Population', 'CPS Population', 'SNAP Population']]\n",
    "d.to_csv('recipients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to impute 209524.181667 for state 1\n",
      "Method1: regression gives 209994.65999999992\n",
      "we need to impute 10445.5433333 for state 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comm6\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\comm6\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method1: regression gives 10689.49\n",
      "we need to impute 186472.2725 for state 4\n",
      "Method1: regression gives 187786.76000000007\n",
      "we need to impute 82032.8841667 for state 5\n",
      "Method1: regression gives 82643.98999999995\n",
      "we need to impute 991790.0525 for state 6\n",
      "Method1: regression gives 991880.3899999993\n",
      "we need to impute 98618.2533333 for state 8\n",
      "Method1: regression gives 97672.07999999996\n",
      "we need to impute 92199.9533333 for state 9\n",
      "Method1: regression gives 92289.55999999997\n",
      "we need to impute 31580.6191667 for state 10\n",
      "Method1: regression gives 31671.419999999995\n",
      "we need to impute 46638.4991667 for state 11\n",
      "Method1: regression gives 46793.46\n",
      "we need to impute 1016327.86833 for state 12\n",
      "Method1: regression gives 1015389.9099999996\n",
      "we need to impute 470009.988333 for state 13\n",
      "Method1: regression gives 469238.2000000005\n",
      "we need to impute 52113.5291667 for state 15\n",
      "Method1: regression gives 52019.73000000002\n",
      "we need to impute 46204.8591667 for state 16\n",
      "Method1: regression gives 46349.099999999984\n",
      "we need to impute 562659.22 for state 17\n",
      "Method1: regression gives 562329.8999999994\n",
      "we need to impute 203441.261667 for state 18\n",
      "Method1: regression gives 202904.50000000006\n",
      "we need to impute 95456.4058333 for state 19\n",
      "Method1: regression gives 95421.04\n",
      "we need to impute 33070.8558333 for state 20\n",
      "Method1: regression gives 32864.37\n",
      "we need to impute 183007.345 for state 21\n",
      "Method1: regression gives 182341.27999999994\n",
      "we need to impute 140992.218333 for state 22\n",
      "Method1: regression gives 140787.45\n",
      "we need to impute 40429.7533333 for state 23\n",
      "Method1: regression gives 40524.049999999996\n",
      "we need to impute 224953.521667 for state 24\n",
      "Method1: regression gives 223525.56\n",
      "we need to impute 182510.4625 for state 25\n",
      "Method1: regression gives 182859.12000000008\n",
      "we need to impute 390474.815833 for state 26\n",
      "Method1: regression gives 389911.5599999998\n",
      "we need to impute 110903.576667 for state 27\n",
      "Method1: regression gives 109843.23\n",
      "we need to impute 116518.998333 for state 28\n",
      "Method1: regression gives 116199.04000000001\n",
      "we need to impute 173690.9575 for state 29\n",
      "Method1: regression gives 174651.78000000003\n",
      "we need to impute 23526.0466667 for state 30\n",
      "Method1: regression gives 23515.220000000005\n",
      "we need to impute 26693.9941667 for state 31\n",
      "Method1: regression gives 26567.989999999998\n",
      "we need to impute 87760.5875 for state 32\n",
      "Method1: regression gives 88062.41\n",
      "we need to impute 20436.345 for state 33\n",
      "Method1: regression gives 20592.589999999997\n",
      "we need to impute 164531.793333 for state 34\n",
      "Method1: regression gives 164455.80999999997\n",
      "we need to impute 109499.915833 for state 35\n",
      "Method1: regression gives 109178.58999999992\n",
      "we need to impute 665210.146667 for state 36\n",
      "Method1: regression gives 665043.4799999999\n",
      "we need to impute 291073.433333 for state 37\n",
      "Method1: regression gives 290426.67999999993\n",
      "we need to impute 7513.20416667 for state 38\n",
      "Method1: regression gives 7560.2699999999995\n",
      "we need to impute 237989.1475 for state 39\n",
      "Method1: regression gives 238846.97000000003\n",
      "we need to impute 154780.046667 for state 40\n",
      "Method1: regression gives 154081.66000000003\n",
      "we need to impute 241659.495 for state 41\n",
      "Method1: regression gives 241567.08\n",
      "we need to impute 332843.756667 for state 42\n",
      "Method1: regression gives 332897.9699999999\n",
      "we need to impute 46518.9475 for state 44\n",
      "Method1: regression gives 46638.37000000001\n",
      "we need to impute 152888.089167 for state 45\n",
      "Method1: regression gives 153225.26000000007\n",
      "we need to impute 12874.5825 for state 46\n",
      "Method1: regression gives 12896.9\n",
      "we need to impute 341835.636667 for state 47\n",
      "Method1: regression gives 342429.31\n",
      "we need to impute 663776.419167 for state 48\n",
      "Method1: regression gives 664230.47\n",
      "we need to impute 26579.575 for state 49\n",
      "Method1: regression gives 27158.18\n",
      "we need to impute 21577.525 for state 50\n",
      "Method1: regression gives 21447.56\n",
      "we need to impute 233908.711667 for state 51\n",
      "Method1: regression gives 234200.65000000005\n",
      "we need to impute 282086.110833 for state 53\n",
      "Method1: regression gives 283219.79000000015\n",
      "we need to impute 51761.7558333 for state 54\n",
      "Method1: regression gives 51641.560000000005\n",
      "we need to impute 178275.045 for state 55\n",
      "Method1: regression gives 177331.83999999997\n",
      "we need to impute 1510.60166667 for state 56\n",
      "Method1: regression gives 1486.3600000000001\n"
     ]
    }
   ],
   "source": [
    "hh_SNAP['impute'] = np.zeros(len(hh_SNAP))\n",
    "hh_SNAP['snap_impute'] = np.zeros(len(hh_SNAP))\n",
    "\n",
    "non_current = (hh_SNAP.indicator==0)\n",
    "current = (hh_SNAP.indicator==1)\n",
    "random.seed()\n",
    "\n",
    "for FIPS in admin.Fips:\n",
    "    \n",
    "        print ('we need to impute', d['Difference in Population'][FIPS], 'for state', FIPS)\n",
    "        \n",
    "        if d['Difference in Population'][FIPS] < 0:\n",
    "            continue\n",
    "        else:\n",
    "            this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "            not_imputed = (hh_SNAP.impute==0)\n",
    "            pool_index = hh_SNAP[this_state&not_imputed&non_current].index\n",
    "            pool = DataFrame({'weight': hh_SNAP.hh_marsupwt[pool_index], 'prob': probs[pool_index]},\n",
    "                            index=pool_index)\n",
    "            pool = pool.sort_values(by='prob', ascending=False)\n",
    "            pool['cumsum_weight'] = pool['weight'].cumsum()\n",
    "            pool['distance'] = abs(pool.cumsum_weight-d['Difference in Population'][FIPS])\n",
    "            min_index = pool.sort_values(by='distance')[:1].index\n",
    "            min_weight = int(pool.loc[min_index].cumsum_weight)\n",
    "            pool['impute'] = np.where(pool.cumsum_weight<=min_weight+10 , 1, 0)\n",
    "            hh_SNAP.impute[pool.index[pool['impute']==1]] = 1\n",
    "            hh_SNAP.snap_impute[pool.index[pool['impute']==1]] = admin['Average household benefit'][FIPS]*12\n",
    "\n",
    "        print ('Method1: regression gives', \n",
    "                hh_SNAP.hh_marsupwt[(hh_SNAP.impute==1)&this_state].sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adjustment ratio\n",
    "results = {}\n",
    "\n",
    "imputed = (hh_SNAP.impute == 1)\n",
    "has_val = (hh_SNAP.hh_hfdval != 0)\n",
    "no_val = (hh_SNAP.hh_hfdval == 0)\n",
    "\n",
    "for FIPS in admin.Fips:\n",
    "    this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "    \n",
    "    current_total = (hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt)[this_state].sum() #yearly benefit\n",
    "    imputed_total = (hh_SNAP.snap_impute * hh_SNAP.hh_marsupwt)[this_state&imputed].sum()\n",
    "    on_file = current_total + imputed_total\n",
    "\n",
    "    admin_total = admin.Total[FIPS]\n",
    "    \n",
    "    adjust_ratio = admin_total / on_file\n",
    "    this_state_num = [admin['State'][FIPS], on_file, admin_total, adjust_ratio]\n",
    "    results[FIPS] = this_state_num\n",
    "    \n",
    "\n",
    "    hh_SNAP.snap_impute = np.where(has_val&this_state, hh_SNAP.hh_hfdval * adjust_ratio, hh_SNAP.snap_impute)\n",
    "    hh_SNAP.snap_impute = np.where(no_val&this_state, hh_SNAP.snap_impute * adjust_ratio, hh_SNAP.snap_impute)\n",
    "\n",
    "hh_SNAP[\"snap_participation\"] = np.zeros(len(hh_SNAP))\n",
    "hh_SNAP[\"snap_participation\"] = np.where(hh_SNAP.impute==1, 2, 0)\n",
    "hh_SNAP[\"snap_participation\"] = np.where(has_val, 1, hh_SNAP.snap_participation)\n",
    "\n",
    "\n",
    "r = DataFrame(results).transpose()\n",
    "r.columns=['State', 'Imputed', 'Admin', 'adjust ratio']\n",
    "r.to_csv('amount.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.to_csv('SNAP_Imputation.csv', \n",
    "                   columns=['snap_participation', 'snap_impute'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
